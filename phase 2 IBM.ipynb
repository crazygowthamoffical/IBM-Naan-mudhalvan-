{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XGX1UXhuHw4z"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset (assuming it's in a CSV file)\n",
        "data = pd.read_csv('/content/NetflixOriginals.csv',encoding='latin-1')\n",
        "\n",
        "# Preprocessing: Handle missing values, encode categorical features, etc.\n",
        "# For simplicity, we'll assume that preprocessing has been done.\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = data[['Runtime']]  # Add relevant features\n",
        "y = data['IMDB Score']\n",
        "\n"
      ],
      "metadata": {
        "id": "AUbOdN7nJCvX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Gradient Boosting Regressor\n",
        "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Train the Gradient Boosting model\n",
        "gb_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "gb_predictions = gb_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the Gradient Boosting model\n",
        "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
        "print(f\"Gradient Boosting Mean Squared Error: {gb_mse}\")\n",
        "\n",
        "# Neural Network model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)  # Output layer with 1 neuron for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the Neural Network model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Make predictions with the Neural Network\n",
        "nn_predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the Neural Network model\n",
        "nn_mse = mean_squared_error(y_test, nn_predictions)\n",
        "print(f\"Neural Network Mean Squared Error: {nn_mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBT-f1oEMLoE",
        "outputId": "b6afd01a-802c-405e-a4cc-10ff007b00ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Mean Squared Error: 1.3134895577600725\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 21ms/step - loss: 22.8295 - val_loss: 4.7137\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.5624 - val_loss: 7.9195\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5.9138 - val_loss: 4.5070\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.5245 - val_loss: 3.5798\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.2183 - val_loss: 3.7476\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.3513 - val_loss: 3.5253\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4.1711 - val_loss: 3.5432\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4.1985 - val_loss: 3.4718\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4.3083 - val_loss: 3.4947\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.4928 - val_loss: 3.5711\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4.1397 - val_loss: 3.4162\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.1070 - val_loss: 3.3435\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.2965 - val_loss: 3.4762\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.0435 - val_loss: 3.6117\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.9644 - val_loss: 3.4124\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.8402 - val_loss: 3.2062\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.8472 - val_loss: 3.4542\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.7637 - val_loss: 3.1745\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.7029 - val_loss: 3.2449\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.7085 - val_loss: 3.1148\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.6253 - val_loss: 3.1050\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6843 - val_loss: 3.5378\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.6795 - val_loss: 3.4181\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.7808 - val_loss: 2.9312\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.8810 - val_loss: 2.9138\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.5217 - val_loss: 3.3187\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.5566 - val_loss: 3.3223\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.3688 - val_loss: 2.8509\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.3914 - val_loss: 2.7831\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.7150 - val_loss: 3.2261\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.3763 - val_loss: 2.6757\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.1539 - val_loss: 2.7158\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.0919 - val_loss: 2.5942\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.0519 - val_loss: 2.5998\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.1181 - val_loss: 2.5694\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.9342 - val_loss: 2.5193\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.0671 - val_loss: 2.4771\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.9184 - val_loss: 2.5027\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.8232 - val_loss: 2.4911\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.7856 - val_loss: 2.3689\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.7314 - val_loss: 2.3598\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.7174 - val_loss: 2.2710\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.6579 - val_loss: 2.2765\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.6399 - val_loss: 2.2954\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.6601 - val_loss: 2.3263\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.7784 - val_loss: 2.1356\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.4578 - val_loss: 2.1616\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.5068 - val_loss: 2.0641\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.5343 - val_loss: 2.1434\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.5412 - val_loss: 2.0357\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Neural Network Mean Squared Error: 2.5606791133337303\n"
          ]
        }
      ]
    }
  ]
}